# audit_model.py
import pandas as pd
import json
import os
import sys
from sklearn.metrics import silhouette_score, davies_bouldin_score
import matplotlib.pyplot as plt

# Importamos tu motor actual
from src.agents.trends.topic_engine import TopicModelEngine

# 1. CARGAR DATOS EXISTENTES
# Cambia esta ruta por un archivo .jsonl que ya tengas con datos reales
INPUT_FILE = "data/preprocessed/Impacto_del_Teletrabajo_en_Salud_Mental_cleaned_with_sentiment.jsonl" 

if not os.path.exists(INPUT_FILE):
    # Si no tienes el archivo exacto, busca cualquiera en la carpeta
    files = [f for f in os.listdir("data/preprocessed") if f.endswith(".jsonl")]
    if files:
        INPUT_FILE = os.path.join("data/preprocessed", files[0])
    else:
        print("âŒ No encontrÃ© archivos de datos en data/preprocessed. Ejecuta run_batch primero.")
        sys.exit()

print(f"ğŸ“Š Auditando modelo con datos de: {INPUT_FILE}")

# Cargar textos
texts = []
with open(INPUT_FILE, 'r', encoding='utf-8') as f:
    for line in f:
        if line.strip():
            obj = json.loads(line)
            # Intentamos leer el texto limpio o el raw
            t = obj.get('text_norm', obj.get('text', ''))
            if len(t) > 20: # Solo textos con algo de contenido
                texts.append(t)

print(f"   Documentos cargados: {len(texts)}")

# 2. EJECUTAR EL MOTOR (Como estÃ¡ configurado actualmente)
engine = TopicModelEngine()
topics, model = engine.fit_transform(texts)
embeddings = model._extract_embeddings(texts, method="document", verbose=False)

# 3. VER LAS "TRIPAS" DEL MODELO (Lo que quiere tu tutor)

print("\n--- ğŸ” INSPECCIÃ“N DE TÃ“PICOS (Stopwords Check) ---")
topic_info = model.get_topic_info()
print(topic_info[['Topic', 'Count', 'Name']].head(10))

print("\n--- ğŸ§ PALABRAS CLAVE DEL TOPIC 0 (El mÃ¡s grande) ---")
# AquÃ­ veremos si hay basura como "el", "la", "que"
print(model.get_topic(0))

# 4. CÃLCULO DE MÃ‰TRICAS CIENTÃFICAS (Rigor AcadÃ©mico)
# Filtramos el ruido (-1) para calcular mÃ©tricas justas
clean_indices = [i for i, t in enumerate(topics) if t != -1]

if len(clean_indices) > 0 and len(set(topics)) > 1:
    clean_embeddings = embeddings[clean_indices]
    clean_topics = [topics[i] for i in clean_indices]
    
    # Silhouette Score: (-1 a 1). Cuanto mÃ¡s alto, mejor definidos estÃ¡n los grupos.
    sil_score = silhouette_score(clean_embeddings, clean_topics)
    
    # Davies-Bouldin: (0 a infinito). Cuanto mÃ¡s BAJO, mejor.
    db_score = davies_bouldin_score(clean_embeddings, clean_topics)
    
    print(f"\n--- ğŸ“ MÃ‰TRICAS DE CALIDAD ---")
    print(f"âœ… Silhouette Score: {sil_score:.4f} (Ideal > 0.1 para texto, >0.4 es excelente)")
    print(f"âœ… Davies-Bouldin Index: {db_score:.4f} (Cuanto mÃ¡s bajo mejor)")
else:
    print("\nâš ï¸ No hay suficientes clusters para calcular mÃ©tricas (todo es ruido o un solo grupo).")

# 5. GENERACIÃ“N DE GRÃFICOS (Para tu tesis)
print("\n--- ğŸ–¼ï¸ GENERANDO GRÃFICOS INTERACTIVOS ---")
output_dir = "auditoria_graficos"
os.makedirs(output_dir, exist_ok=True)

try:
    # GrÃ¡fico de Barras (Palabras clave)
    fig1 = model.visualize_barchart(top_n_topics=5)
    fig1.write_html(f"{output_dir}/barchart_words.html")
    print(f"   --> {output_dir}/barchart_words.html")

    # Mapa de Distancia (CÃ³mo se separan los temas)
    fig2 = model.visualize_topics()
    fig2.write_html(f"{output_dir}/intertopic_map.html")
    print(f"   --> {output_dir}/intertopic_map.html")
    
except Exception as e:
    print(f"Error generando grÃ¡ficos: {e}")

print("\nğŸ AuditorÃ­a finalizada. Abre los HTML en tu navegador.")